{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c616e85a-5553-493d-886b-f9cc9fc810e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pyspark import SparkContext\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92cac0e0-94b8-4d99-8802-e97e680516f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x000001741A849DE0>\n",
      "<SparkContext master=local[*] appName=df-project>\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('test').getOrCreate()\n",
    "print(spark)\n",
    "sc = spark.sparkContext\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36381c3c-c06b-4f06-9a4e-9082c206f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "|      Year|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|95thPercentile|   base_measureid|sub_measureid|   base_measuredesc|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "|HEDIS_2021|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid1|         IMA4|cs_basemeasuredesc1|\n",
      "|HEDIS_2022|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid2|        CIS12|cs_basemeasuredesc2|\n",
      "|HEDIS_2021|   VA|Medicaid|Benchmarkcategory3| test3|averageName3|           53|           103|           253|              333|           503|              663|           753|           903|           953|cs_basemeasureid3|        CIS12|cs_basemeasuredesc3|\n",
      "|HEDIS_2021|   OH|Medicaid|Benchmarkcategory4| test4|averageName4|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid4|         IMA4|cs_basemeasuredesc4|\n",
      "|HEDIS_2022|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid5|        CIS12|cs_basemeasuredesc5|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "\n",
      "+-------+----------+-----+--------+------------------+------+------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+-------------+-------------------+\n",
      "|summary|      Year|State|     LOB|Benchmark_category|source| averageName|     5thpercentile|    10thpercentile|    25thPercentile| 33_33thPercentile|    50thPercentile| 66_67thPercentile|    75thPercentile|    90thPercentile|   95thPercentile|   base_measureid|sub_measureid|   base_measuredesc|\n",
      "+-------+----------+-----+--------+------------------+------+------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+-------------+-------------------+\n",
      "|  count|         5|    5|       5|                 5|     5|           5|                 5|                 5|                 5|                 5|                 5|                 5|                 5|                 5|                5|                5|            5|                  5|\n",
      "|   mean|      null| null|    null|              null|  null|        null|              51.8|             101.8|             251.8|             331.8|             501.8|             661.8|             751.8|             901.8|            571.8|             null|         null|               null|\n",
      "| stddev|      null| null|    null|              null|  null|        null|0.8366600265340756|0.8366600265340756|0.8366600265340756|0.8366600265340756|0.8366600265340756|0.8366600265340756|0.8366600265340756|0.8366600265340756|521.0668863015572|             null|         null|               null|\n",
      "|    min|HEDIS_2021|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|                51|               101|               251|               331|               501|               661|               751|               901|               01|cs_basemeasureid1|        CIS12|cs_basemeasuredesc1|\n",
      "|    25%|      null| null|    null|              null|  null|        null|              51.0|             101.0|             251.0|             331.0|             501.0|             661.0|             751.0|             901.0|              1.0|             null|         null|               null|\n",
      "|    50%|      null| null|    null|              null|  null|        null|              52.0|             102.0|             252.0|             332.0|             502.0|             662.0|             752.0|             902.0|            952.0|             null|         null|               null|\n",
      "|    75%|      null| null|    null|              null|  null|        null|              52.0|             102.0|             252.0|             332.0|             502.0|             662.0|             752.0|             902.0|            952.0|             null|         null|               null|\n",
      "|    max|HEDIS_2022|   VA|Medicaid|Benchmarkcategory5| test5|averageName5|                53|               103|               253|               333|               503|               663|               753|               903|              953|cs_basemeasureid5|         IMA4|cs_basemeasuredesc5|\n",
      "+-------+----------+-----+--------+------------------+------+------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+-----------------+-----------------+-------------+-------------------+\n",
      "\n",
      "+----------+----------+----------+----------+\n",
      "|      Year|      Year|      Year|     Year1|\n",
      "+----------+----------+----------+----------+\n",
      "|HEDIS_2021|HEDIS_2021|HEDIS_2021|HEDIS_2021|\n",
      "|HEDIS_2022|HEDIS_2022|HEDIS_2022|HEDIS_2022|\n",
      "|HEDIS_2021|HEDIS_2021|HEDIS_2021|HEDIS_2021|\n",
      "|HEDIS_2021|HEDIS_2021|HEDIS_2021|HEDIS_2021|\n",
      "|HEDIS_2022|HEDIS_2022|HEDIS_2022|HEDIS_2022|\n",
      "+----------+----------+----------+----------+\n",
      "\n",
      "+----------+-----------+\n",
      "|      Year|lower(Year)|\n",
      "+----------+-----------+\n",
      "|HEDIS_2021| hedis_2021|\n",
      "|HEDIS_2022| hedis_2022|\n",
      "|HEDIS_2021| hedis_2021|\n",
      "|HEDIS_2021| hedis_2021|\n",
      "|HEDIS_2022| hedis_2022|\n",
      "+----------+-----------+\n",
      "\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+-----+\n",
      "|      Year|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|95thPercentile|   base_measureid|sub_measureid|   base_measuredesc|Year1|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+-----+\n",
      "|HEDIS_2021|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid1|         IMA4|cs_basemeasuredesc1|HEDIS|\n",
      "|HEDIS_2022|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid2|        CIS12|cs_basemeasuredesc2|HEDIS|\n",
      "|HEDIS_2021|   VA|Medicaid|Benchmarkcategory3| test3|averageName3|           53|           103|           253|              333|           503|              663|           753|           903|           953|cs_basemeasureid3|        CIS12|cs_basemeasuredesc3|HEDIS|\n",
      "|HEDIS_2021|   OH|Medicaid|Benchmarkcategory4| test4|averageName4|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid4|         IMA4|cs_basemeasuredesc4|HEDIS|\n",
      "|HEDIS_2022|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid5|        CIS12|cs_basemeasuredesc5|HEDIS|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+-----+\n",
      "\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "|     Year2|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|95thPercentile|   base_measureid|sub_measureid|   base_measuredesc|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "|HEDIS_2021|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid1|         IMA4|cs_basemeasuredesc1|\n",
      "|HEDIS_2022|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid2|        CIS12|cs_basemeasuredesc2|\n",
      "|HEDIS_2021|   VA|Medicaid|Benchmarkcategory3| test3|averageName3|           53|           103|           253|              333|           503|              663|           753|           903|           953|cs_basemeasureid3|        CIS12|cs_basemeasuredesc3|\n",
      "|HEDIS_2021|   OH|Medicaid|Benchmarkcategory4| test4|averageName4|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid4|         IMA4|cs_basemeasuredesc4|\n",
      "|HEDIS_2022|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid5|        CIS12|cs_basemeasuredesc5|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "\n",
      "+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|95thPercentile|   base_measureid|sub_measureid|   base_measuredesc|\n",
      "+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid1|         IMA4|cs_basemeasuredesc1|\n",
      "|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid2|        CIS12|cs_basemeasuredesc2|\n",
      "|   VA|Medicaid|Benchmarkcategory3| test3|averageName3|           53|           103|           253|              333|           503|              663|           753|           903|           953|cs_basemeasureid3|        CIS12|cs_basemeasuredesc3|\n",
      "|   OH|Medicaid|Benchmarkcategory4| test4|averageName4|           51|           101|           251|              331|           501|              661|           751|           901|            01|cs_basemeasureid4|         IMA4|cs_basemeasuredesc4|\n",
      "|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|           952|cs_basemeasureid5|        CIS12|cs_basemeasuredesc5|\n",
      "+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+--------------+-----------------+-------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select Apis And functions\n",
    "ord = spark.read.load('D:\\SpectraMD\\Feed\\Benchmarks',sep=\"|\",format=\"csv\",header=True)#,schema= ('Year string,State  string,     LOB string,Benchmark_category string,source string, averageName string,5thpercentile string,10thpercentile string,25thPercentile string,33_33thPercentile string,50thPercentile string,66_67thPercentile int,75thPercentile int,90thPercentile int'))\n",
    "ord.show()\n",
    " \n",
    "ord.summary().show()\n",
    "\n",
    "#select Apis , fetching cols in multiples ways\n",
    "ord.select(ord.Year,'Year',\"Year\",(ord.Year).alias(\"Year1\")).show()\n",
    "\n",
    "#Applying sql functions on the columns \n",
    "from pyspark.sql.functions import lower\n",
    "ord.select('Year',lower(ord.Year)).show()\n",
    "\n",
    "#Withcolumns\n",
    "from pyspark.sql.functions import substring\n",
    "ord.withColumn('Year1',substring(ord.Year,1,5)).show()\n",
    "\n",
    "#withColumnRenamed\n",
    "ord.withColumnRenamed('Year','Year2').show()\n",
    "\n",
    "#drop \n",
    "ord.drop('Year').show()\n",
    "\n",
    "#Drop Duplicate : drops duplicate rows. optional subset of the columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b64942d1-3268-4a5f-b347-5d796e0c79e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|      Year|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|HEDIS_2021|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|           51|           101|           251|              331|           501|              661|           751|           901|\n",
      "|HEDIS_2022|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "|HEDIS_2021|   VA|Medicaid|Benchmarkcategory3| test3|averageName3|           53|           103|           253|              333|           503|              663|           753|           903|\n",
      "|HEDIS_2021|   OH|Medicaid|Benchmarkcategory4| test4|averageName4|           51|           101|           251|              331|           501|              661|           751|           901|\n",
      "|HEDIS_2022|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|      Year|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|HEDIS_2022|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "|HEDIS_2022|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filter\n",
    "ord = spark.read.load('D:\\SpectraMD\\Feed\\Benchmarks',sep=\"|\",format=\"csv\",header=True,schema= ('Year string,State  string,     LOB string,Benchmark_category string,source string, averageName string,5thpercentile string,10thpercentile string,25thPercentile string,33_33thPercentile string,50thPercentile string,66_67thPercentile int,75thPercentile int,90thPercentile int'))\n",
    "ord.show()\n",
    "\n",
    "#Filter rows using where conditions. use &  and |f\n",
    "from pyspark.sql.functions import col\n",
    "ord.where((col('75thPercentile') > 751) & (col('75thPercentile') < 753)).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39d38ee3-2d92-4fe8-8a94-9288208c46d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "+---+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "+---+\n",
      "\n",
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "+----+----+\n",
      "\n",
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   b|   2|\n",
      "|   c|   3|\n",
      "+----+----+\n",
      "\n",
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "+----+----+\n",
      "\n",
      "+----+----+\n",
      "|col1|col2|\n",
      "+----+----+\n",
      "|   a|   1|\n",
      "|   a|   1|\n",
      "+----+----+\n",
      "\n",
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#union\n",
    "df1=spark.range(10)\n",
    "df2=spark.range(5,15)\n",
    "df1.union(df2).show()\n",
    "\n",
    "#union Addll ignore the duplicates \n",
    "df1.unionAll(df2).show()\n",
    "\n",
    "#unionByName\n",
    "df1=spark.createDataFrame(data=[('a',1),('b',2)],schema=('col1 string, col2 int'))\n",
    "df2=spark.createDataFrame(data=[(2,'b'),(3,'c')],schema=('col2 int, col1 string'))\n",
    "df1.unionByName(df2).show()\n",
    "\n",
    "#To remove the duplicates \n",
    "df1=spark.createDataFrame(data=[('a',1),('b',2)],schema=('col1 string, col2 int'))\n",
    "df2=spark.createDataFrame(data=[(2,'b'),(3,'c')],schema=('col2 int, col1 string'))\n",
    "df1.unionByName(df2).distinct().show()\n",
    "\n",
    "#intersect -> remove the duplicates\n",
    "df1=spark.createDataFrame(data=[('a',1),('a',1),('b',2)],schema=('col1 string, col2 int'))\n",
    "df2=spark.createDataFrame(data=[('a',1),('a',1),('c',2)],schema=('col1 string, col2 int'))\n",
    "df1.intersect(df2).show()\n",
    "\n",
    "#intersectAll -> Retain the duplicates \n",
    "df1=spark.createDataFrame(data=[('a',1),('a',1),('b',2)],schema=('col1 string, col2 int'))\n",
    "df2=spark.createDataFrame(data=[('a',1),('a',1),('c',2)],schema=('col1 string, col2 int'))\n",
    "df1.intersectAll(df2).show()\n",
    "\n",
    "#exceptAll \n",
    "df1=spark.range(1,10)\n",
    "df2=spark.range(5,10)\n",
    "df1.exceptAll(df2).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10c340f8-bd55-4562-b72e-ebfed2a71535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+\n",
      "|empid|empname|empid|country|\n",
      "+-----+-------+-----+-------+\n",
      "|    1| Robert|    1|    USA|\n",
      "+-----+-------+-----+-------+\n",
      "\n",
      "+-----+-------+-----+-------+\n",
      "|empid|empname|empid|country|\n",
      "+-----+-------+-----+-------+\n",
      "|    1| Robert|    1|    USA|\n",
      "|    2|    Kia| null|   null|\n",
      "|    3|  James| null|   null|\n",
      "+-----+-------+-----+-------+\n",
      "\n",
      "+-----+-------+-----+-------+\n",
      "|empid|empname|empid|country|\n",
      "+-----+-------+-----+-------+\n",
      "|    1| Robert|    1|    USA|\n",
      "| null|   null|    4|  INDIA|\n",
      "+-----+-------+-----+-------+\n",
      "\n",
      "+-----+-------+-----+-------+\n",
      "|empid|empname|empid|country|\n",
      "+-----+-------+-----+-------+\n",
      "|    1| Robert|    1|    USA|\n",
      "|    2|    Kia| null|   null|\n",
      "|    3|  James| null|   null|\n",
      "| null|   null|    4|  INDIA|\n",
      "+-----+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#JOINS\n",
    "df1 = spark.createDataFrame(data=[(1,'Robert'),(2,'Kia'),(3,'James')],schema=('empid int, empname string'))\n",
    "df2 = spark.createDataFrame(data=[(1,'USA'),(4,'INDIA')],schema=('empid int, country string'))\n",
    "\n",
    "#inner join : Common rows : bydefault join api takes inner \n",
    "df1.join(df2,df1.empid == df2.empid).show()\n",
    "\n",
    "#left join : left + common \n",
    "df1.join(df2,df1.empid == df2.empid,'left').show()\n",
    "\n",
    "#right join : right + common \n",
    "df1.join(df2,df1.empid == df2.empid,'right').show()\n",
    "\n",
    "#full join: right + left\n",
    "df1.join(df2,df1.empid == df2.empid,'full').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12b45981-bd56-432c-b681-62dc2ac87661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+\n",
      "|empid|empname|empid|country|\n",
      "+-----+-------+-----+-------+\n",
      "|    1| Robert|    1|    USA|\n",
      "+-----+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cross : did worked properly need to check \n",
    "df1.join(df2,df1.empid == df2.empid,'cross').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0a28b8d-fce2-49f5-b7c2-d6164138f06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+\n",
      "|empid|empname|\n",
      "+-----+-------+\n",
      "|    1| Robert|\n",
      "+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#leftsemi similar to inner join only access the column from left df more efficient\n",
    "df1 = spark.createDataFrame(data=[(1,'Robert'),(2,'Kia'),(3,'James')],schema=('empid int, empname string'))\n",
    "df2 = spark.createDataFrame(data=[(1,'USA'),(4,'INDIA')],schema=('empid int, country string'))\n",
    "df1.join(df2,df1.empid == df2.empid,'leftsemi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32a72dbf-02fd-4b74-8041-cda0b2658396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+\n",
      "|empid|empname|empid|country|\n",
      "+-----+-------+-----+-------+\n",
      "|    1| Robert|    1|    USA|\n",
      "|    1| Robert|    4|  INDIA|\n",
      "|    2|    Kia|    1|    USA|\n",
      "|    2|    Kia|    4|  INDIA|\n",
      "|    3|  James|    1|    USA|\n",
      "|    3|  James|    4|  INDIA|\n",
      "+-----+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Cross join usinf different syntax\n",
    "df1.crossJoin(df2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe5eb49e-d2b8-4362-b46b-6e29c4c9d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+---------+-----------+\n",
      "|empId|empname|managerId|managerName|\n",
      "+-----+-------+---------+-----------+\n",
      "|    1| Robert|        2|        Kia|\n",
      "|    2|    Kia|        3|      James|\n",
      "+-----+-------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#self Join : join with same table\n",
    "from pyspark.sql.functions import col\n",
    "df1 = spark.createDataFrame(data=[(1,'Robert',2),(2,'Kia',3),(3,'James',5)],schema=('empid int, empname string,managerId int'))\n",
    "df1.alias(\"emp1\").join(df1.alias(\"emp2\"),col(\"emp1.managerId\") == col(\"emp2.empid\"),\"inner\").select(col(\"emp1.empId\"),col(\"emp1.empname\"),col(\"emp2.empid\").alias(\"managerId\"),col(\"emp2.empname\").alias(\"managerName\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59d4e5b-e7e1-4d7c-8eee-50cc1cf14e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+------+\n",
      "|empid|empname|deptid|\n",
      "+-----+-------+------+\n",
      "|    1| Robert|     3|\n",
      "+-----+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Join on multiple columns \n",
    "df1 = spark.createDataFrame(data=[(1,'Robert',3),(2,'Kia',4),(3,'James',5)],schema=('empid int, empname string,deptid int'))\n",
    "df2 = spark.createDataFrame(data=[(1,'USA',3),(4,'INDIA',4)],schema=('empid int, country string, deptid int'))\n",
    "df1.join(df2,(df1.empid == df2.empid) & (df1.deptid == df2.deptid) ,'leftsemi').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c19e066-326e-42be-bbe1-69eb2422fa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|      Year|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|HEDIS_2021|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|           51|           101|           251|              331|           501|              661|           751|           901|\n",
      "|HEDIS_2022|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "|HEDIS_2021|   VA|Medicaid|Benchmarkcategory3| test3|averageName3|           53|           103|           253|              333|           503|              663|           753|           903|\n",
      "|HEDIS_2021|   OH|Medicaid|Benchmarkcategory4| test4|averageName4|           51|           101|           251|              331|           501|              661|           751|           901|\n",
      "|HEDIS_2022|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "\n",
      "+----------------------+\n",
      "|avg(33_33thPercentile)|\n",
      "+----------------------+\n",
      "|                 331.8|\n",
      "+----------------------+\n",
      "\n",
      "+----------------------+\n",
      "|max(33_33thPercentile)|\n",
      "+----------------------+\n",
      "|                   333|\n",
      "+----------------------+\n",
      "\n",
      "+----------------------+\n",
      "|min(33_33thPercentile)|\n",
      "+----------------------+\n",
      "|                   331|\n",
      "+----------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\SpectraMD\\spark-3.4.1-bin-hadoop3\\python\\pyspark\\sql\\functions.py:752: FutureWarning: Deprecated in 3.2, use sum_distinct instead.\n",
      "  warnings.warn(\"Deprecated in 3.2, use sum_distinct instead.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------------------+\n",
      "|sum(33_33thPercentile)|sum(DISTINCT 33_33thPercentile)|\n",
      "+----------------------+-------------------------------+\n",
      "|                1659.0|                          996.0|\n",
      "+----------------------+-------------------------------+\n",
      "\n",
      "+------------------------+---------------------------------+\n",
      "|count(33_33thPercentile)|count(DISTINCT 33_33thPercentile)|\n",
      "+------------------------+---------------------------------+\n",
      "|                       5|                                3|\n",
      "+------------------------+---------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Aggregations Api\n",
    "#Avg, max , min\n",
    "benchmark = spark.read.load('D:\\SpectraMD\\Feed\\Benchmarks',sep=\"|\",format=\"csv\",header=True,schema= ('Year string,State  string,     LOB string,Benchmark_category string,source string, averageName string,5thpercentile string,10thpercentile string,25thPercentile string,33_33thPercentile string,50thPercentile string,66_67thPercentile int,75thPercentile int,90thPercentile int'))\n",
    "benchmark.show()\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "benchmark.select(avg(col(\"33_33thPercentile\"))).show()\n",
    "\n",
    "#max\n",
    "benchmark.select(max(col(\"33_33thPercentile\"))).show()\n",
    "\n",
    "#min\n",
    "benchmark.select(min(col(\"33_33thPercentile\"))).show()\n",
    "\n",
    "#sum sum of all the value .sumDistinct sum of all the distinct values\n",
    "benchmark.select(sum(col(\"33_33thPercentile\")),sumDistinct(col(\"33_33thPercentile\"))).show()\n",
    "\n",
    "#count CountDistinct\n",
    "benchmark.select(count(col(\"33_33thPercentile\")),countDistinct(col(\"33_33thPercentile\"))).show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b16aad3-fc55-47e2-9a07-01e2cced349c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|      Year|State|     LOB|Benchmark_category|source| averageName|5thpercentile|10thpercentile|25thPercentile|33_33thPercentile|50thPercentile|66_67thPercentile|75thPercentile|90thPercentile|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "|HEDIS_2021|   FL|Medicaid|Benchmarkcategory1| test1|averageName1|           51|           101|           251|              331|           501|              661|           751|           901|\n",
      "|HEDIS_2022|   FL|Medicaid|Benchmarkcategory2| test2|averageName2|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "|HEDIS_2021|   VA|Medicaid|Benchmarkcategory3| test3|averageName3|           53|           103|           253|              333|           503|              663|           753|           903|\n",
      "|HEDIS_2021|   OH|Medicaid|Benchmarkcategory4| test4|averageName4|           51|           101|           251|              331|           501|              661|           751|           901|\n",
      "|HEDIS_2022|   OH|Medicaid|Benchmarkcategory5| test5|averageName5|           52|           102|           252|              332|           502|              662|           752|           902|\n",
      "+----------+-----+--------+------------------+------+------------+-------------+--------------+--------------+-----------------+--------------+-----------------+--------------+--------------+\n",
      "\n",
      "+------------------------+-----------------------+\n",
      "|first(33_33thPercentile)|last(33_33thPercentile)|\n",
      "+------------------------+-----------------------+\n",
      "|                     331|                    332|\n",
      "+------------------------+-----------------------+\n",
      "\n",
      "+-------------------------------+------------------------------+\n",
      "|collect_list(33_33thPercentile)|collect_set(33_33thPercentile)|\n",
      "+-------------------------------+------------------------------+\n",
      "|           [331, 332, 333, 3...|               [331, 333, 332]|\n",
      "+-------------------------------+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmark = spark.read.load('D:\\SpectraMD\\Feed\\Benchmarks',sep=\"|\",format=\"csv\",header=True,schema= ('Year string,State  string,     LOB string,Benchmark_category string,source string, averageName string,5thpercentile string,10thpercentile string,25thPercentile string,33_33thPercentile string,50thPercentile string,66_67thPercentile int,75thPercentile int,90thPercentile int'))\n",
    "benchmark.show()\n",
    "from pyspark.sql.functions import *\n",
    "#first get the first record value , last get the lat value of the record value\n",
    "benchmark.select(first(col(\"33_33thPercentile\")),last(col(\"33_33thPercentile\"))).show()\n",
    "\n",
    "#Collect_list(contain all the values) & collect_set(collect unique values)\n",
    "benchmark.select(collect_list(col(\"33_33thPercentile\")),collect_set(col(\"33_33thPercentile\"))).show()\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10d8828c-6eac-410d-aba9-ddaf55201b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+-----+------+---+\n",
      "|empname|     dept|state|salary|age|\n",
      "+-------+---------+-----+------+---+\n",
      "|  James|    Sales|   NY|  9000| 34|\n",
      "| Alicia|    Sales|   NY|  8600| 56|\n",
      "| Robert|    Sales|   CA|  8100| 30|\n",
      "|   Lina|  Finance|   CA|  9000| 24|\n",
      "|   Deja|  Finance|   CA|  9900| 40|\n",
      "|  Sugie|  Finance|   NY|  8300| 36|\n",
      "|    Ram|  Finance|   NY|  7900| 53|\n",
      "|   Kyle|Marketing|   CA|  8000| 25|\n",
      "|   Reid|Marketing|   NY|  9100| 50|\n",
      "+-------+---------+-----+------+---+\n",
      "\n",
      "+---------+-----------------+\n",
      "|     dept|      avg(salary)|\n",
      "+---------+-----------------+\n",
      "|    Sales|8566.666666666666|\n",
      "|  Finance|           8775.0|\n",
      "|Marketing|           8550.0|\n",
      "+---------+-----------------+\n",
      "\n",
      "+---------+-----------+\n",
      "|     dept|sum(salary)|\n",
      "+---------+-----------+\n",
      "|    Sales|      25700|\n",
      "|  Finance|      35100|\n",
      "|Marketing|      17100|\n",
      "+---------+-----------+\n",
      "\n",
      "+---------+-----------+\n",
      "|     dept|max(salary)|\n",
      "+---------+-----------+\n",
      "|    Sales|       9000|\n",
      "|  Finance|       9900|\n",
      "|Marketing|       9100|\n",
      "+---------+-----------+\n",
      "\n",
      "+---------+-----+-----------+--------+\n",
      "|     dept|state|min(salary)|min(age)|\n",
      "+---------+-----+-----------+--------+\n",
      "|    Sales|   NY|       8600|      34|\n",
      "|    Sales|   CA|       8100|      30|\n",
      "|  Finance|   CA|       9000|      24|\n",
      "|  Finance|   NY|       7900|      36|\n",
      "|Marketing|   NY|       9100|      50|\n",
      "|Marketing|   CA|       8000|      25|\n",
      "+---------+-----+-----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#GROUP BY\n",
    "data = [('James','Sales','NY',9000,34),\n",
    "        ('Alicia','Sales','NY',8600,56),\n",
    "        ('Robert','Sales','CA',8100,30),\n",
    "        ('Lina','Finance','CA',9000,24),\n",
    "        ('Deja','Finance','CA',9900,40),\n",
    "        ('Sugie','Finance','NY',8300,36),\n",
    "        ('Ram','Finance','NY',7900,53),\n",
    "        ('Kyle','Marketing','CA',8000,25),\n",
    "        ('Reid','Marketing','NY',9100,50)]\n",
    "schema = [\"empname\",\"dept\",\"state\",\"salary\",\"age\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "df.show()\n",
    "\n",
    "#avg\n",
    "df.groupBy(df.dept).avg(\"salary\").show()\n",
    "\n",
    "#sum\n",
    "df.groupBy(df.dept).sum(\"salary\").show()\n",
    "\n",
    "#max\n",
    "df.groupBy(df.dept).max(\"salary\").show()\n",
    "\n",
    "#multiples columns \n",
    "df.groupBy(df.dept,df.state).min(\"salary\",\"age\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b63037eb-2700-42bd-b747-06ddcc33c9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+-----------------+\n",
      "|     dept|min(salary)|max(salary)|      avg(salary)|\n",
      "+---------+-----------+-----------+-----------------+\n",
      "|    Sales|       8100|       9000|8566.666666666666|\n",
      "|  Finance|       7900|       9900|           8775.0|\n",
      "|Marketing|       8000|       9100|           8550.0|\n",
      "+---------+-----------+-----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Agg -> used for applying multiple agg function\n",
    "df.groupBy(df.dept).agg(min(\"salary\"),max(\"salary\"),avg(\"salary\")).show()\n",
    "\n",
    "#Note : filter has to applied before the aggregation if you want apply after the agg then on ly\n",
    "# apply on the column used in agg function \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9215485-0e87-49e6-a51a-bc95fb322541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+-----------+\n",
      "|     dept|state|sum(salary)|\n",
      "+---------+-----+-----------+\n",
      "|    Sales|   NY|      17600|\n",
      "|    Sales|   CA|       8100|\n",
      "|  Finance|   CA|      18900|\n",
      "|  Finance|   NY|      16200|\n",
      "|Marketing|   NY|       9100|\n",
      "|Marketing|   CA|       8000|\n",
      "+---------+-----+-----------+\n",
      "\n",
      "+---------+-----+-----+\n",
      "|     dept|   CA|   NY|\n",
      "+---------+-----+-----+\n",
      "|    Sales| 8100|17600|\n",
      "|  Finance|18900|16200|\n",
      "|Marketing| 8000| 9100|\n",
      "+---------+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pivot : transfer rows in to columns \n",
    "df = df.select(df.dept,df.state,df.salary)\n",
    "df1 = df.groupBy(df.dept,df.state).sum(\"salary\").alias(\"salary\")\n",
    "df1.show()\n",
    "\n",
    "#applying pivot function\n",
    "df1.groupBy(df1.dept).pivot(\"state\").sum(\"sum(salary)\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45714925-2761-41fc-b6db-f8ed158aa375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+---------------+\n",
      "|     dept|salary|row_number_rank|\n",
      "+---------+------+---------------+\n",
      "|  Finance|  9900|              1|\n",
      "|  Finance|  9000|              2|\n",
      "|  Finance|  8300|              3|\n",
      "|  Finance|  7900|              4|\n",
      "|Marketing|  9100|              1|\n",
      "|Marketing|  8000|              2|\n",
      "|    Sales|  9000|              1|\n",
      "|    Sales|  8600|              2|\n",
      "|    Sales|  8100|              3|\n",
      "+---------+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Windows function\n",
    "from pyspark.sql.window import *\n",
    "from pyspark.sql.functions import *\n",
    "data = [('James','Sales','NY',9000,34),\n",
    "        ('Alicia','Sales','NY',8600,56),\n",
    "        ('Robert','Sales','CA',8100,30),\n",
    "        ('Lina','Finance','CA',9000,24),\n",
    "        ('Deja','Finance','CA',9900,40),\n",
    "        ('Sugie','Finance','NY',8300,36),\n",
    "        ('Ram','Finance','NY',7900,53),\n",
    "        ('Kyle','Marketing','CA',8000,25),\n",
    "        ('Reid','Marketing','NY',9100,50)]\n",
    "schema = [\"empname\",\"dept\",\"state\",\"salary\",\"age\"]\n",
    "df = spark.createDataFrame(data,schema)\n",
    "#df.show()\n",
    "spec = Window.partitionBy(\"dept\").orderBy(df.salary.desc())\n",
    "df1 = df.select(df.dept,df.salary)\n",
    "#df1.show()\n",
    "\n",
    "#df.select(df.dept,df.salary).withColumn(\"row_number_rank\",row_number().over(spec)).show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9881074-8536-4876-a1c0-56343ea01eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
